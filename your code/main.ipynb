{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Board Scraping Lab\n",
    "\n",
    "In this lab you will first see a minimal but fully functional code snippet to scrape the LinkedIn Job Search webpage. You will then work on top of the example code and complete several chanllenges.\n",
    "\n",
    "### Some Resources \n",
    "\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search(keywords):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    # Assemble the full url with parameters\n",
    "    scrape_url = ''.join([BASE_URL, 'keywords=', keywords])\n",
    "\n",
    "    # Create a request to get the data from the server \n",
    "    page = requests.get(scrape_url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "    # Then in each job card, extract the job title, company, and location data.\n",
    "    titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    records = []\n",
    "    for card in soup.select(\"div.job-search-card\"):\n",
    "        title = card.select(\"h3\", recursive=False)[0].get_text().strip()\n",
    "        company = card.select(\"h4\", recursive=False)[0].get_text().strip()\n",
    "        location = card.select(\"span.job-search-card__location\")[0].get_text().strip()\n",
    "        titles.append(title)\n",
    "        companies.append(company)\n",
    "        locations.append(location)\n",
    "\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"Company\": company,\n",
    "            \"Location\": location\n",
    "        })\n",
    "    \n",
    "    # Return dataframe\n",
    "    return pd.DataFrame(records, columns=[\"Title\", \"Company\", \"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Research Data Analyst</td>\n",
       "      <td>UCLA</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Petroplan</td>\n",
       "      <td>Houston, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>The Value Maximizer</td>\n",
       "      <td>New Jersey, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>The Value Maximizer</td>\n",
       "      <td>Pennsylvania, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Nestl√©</td>\n",
       "      <td>Solon, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Intern (Winter or Summer 2026)</td>\n",
       "      <td>Notion</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trading Analyst</td>\n",
       "      <td>Cantor Fitzgerald</td>\n",
       "      <td>New York City Metropolitan Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>City National Bank</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Intern (Winter or Summer 2026)</td>\n",
       "      <td>Notion</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Engineer - Entry Level</td>\n",
       "      <td>InterWorks</td>\n",
       "      <td>Portland, OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Senior Data Analyst - Remote</td>\n",
       "      <td>Experian</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Science Co-Op (NLP &amp; GenAI)</td>\n",
       "      <td>Bose Corporation</td>\n",
       "      <td>Framingham, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jr Data Scientist/Analyst (Power BI)</td>\n",
       "      <td>Crew</td>\n",
       "      <td>Richfield, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Analytics Engineer Co-op</td>\n",
       "      <td>Bose Corporation</td>\n",
       "      <td>Framingham, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Analyst (Business Intelligence)</td>\n",
       "      <td>Philips</td>\n",
       "      <td>Malvern, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Engineer - Entry Level</td>\n",
       "      <td>InterWorks</td>\n",
       "      <td>Tulsa, OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Visualization Specialist</td>\n",
       "      <td>A3T (Agil3 Technology Solutions)</td>\n",
       "      <td>Washington, DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Engineer - Entry Level</td>\n",
       "      <td>InterWorks</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PowerBI/PowerApp Engineer</td>\n",
       "      <td>Toyota North America</td>\n",
       "      <td>Plano, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Largeton Group</td>\n",
       "      <td>Richmond, VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Analyst Lead</td>\n",
       "      <td>Datafied</td>\n",
       "      <td>Anaheim, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MLabs</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Science Graduate</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>Spring, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Toyota North America</td>\n",
       "      <td>Plano, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Associate, CPS&amp;O</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Business Data Scientist, Machine Learning</td>\n",
       "      <td>Google</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Talent Groups</td>\n",
       "      <td>Massachusetts, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Football Operations Assistant</td>\n",
       "      <td>Dallas Bulls</td>\n",
       "      <td>Dallas, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Business Operations Analyst (Remote)</td>\n",
       "      <td>DataBank</td>\n",
       "      <td>Dallas, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Data Analyst (Excel and Power BI) - Hybrid - B...</td>\n",
       "      <td>ideaHelix</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>City National Bank</td>\n",
       "      <td>Newark, DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Analytics and Reporting</td>\n",
       "      <td>U.S. Bank</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Prime 8 Consulting</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Business Data Scientist, Machine Learning</td>\n",
       "      <td>Google</td>\n",
       "      <td>Washington, DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Shaker Recruitment Marketing</td>\n",
       "      <td>Oak Park, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Data Analyst (Remote)</td>\n",
       "      <td>Desire Home Care</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Data Engineer Co-Op</td>\n",
       "      <td>Bose Corporation</td>\n",
       "      <td>Framingham, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Toyota North America</td>\n",
       "      <td>Plano, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Digital Prospectors</td>\n",
       "      <td>Greater Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Washington, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>New York, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Data Visualization Developer Analyst</td>\n",
       "      <td>H&amp;R Block</td>\n",
       "      <td>Missouri, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>New Jersey, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Air Apps</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Data Science Intern, Decisions - Product (Summ...</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>San Francisco County, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Reporting Analyst</td>\n",
       "      <td>Stefanini North America and APAC</td>\n",
       "      <td>Newark, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>United Wheels Inc.</td>\n",
       "      <td>Miamisburg, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Texas, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Analista de Datos Estad√≠sticos</td>\n",
       "      <td>trabajito</td>\n",
       "      <td>Santa Cruz, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Florida, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Data Scientist (Entry Level)</td>\n",
       "      <td>ICF</td>\n",
       "      <td>Reston, VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Illinois, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Verse Medical</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Foster City, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Data Analytics Consultant Intern</td>\n",
       "      <td>Allstate</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Georgia, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Ohio, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Maryland, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                               Research Data Analyst   \n",
       "1                                        Data Analyst   \n",
       "2                                      Data Scientist   \n",
       "3                                      Data Scientist   \n",
       "4                                    Business Analyst   \n",
       "5         Data Science Intern (Winter or Summer 2026)   \n",
       "6                                     Trading Analyst   \n",
       "7                                      Data Analyst I   \n",
       "8         Data Science Intern (Winter or Summer 2026)   \n",
       "9                         Data Engineer - Entry Level   \n",
       "10                       Senior Data Analyst - Remote   \n",
       "11                   Data Science Co-Op (NLP & GenAI)   \n",
       "12               Jr Data Scientist/Analyst (Power BI)   \n",
       "13                      Data Analytics Engineer Co-op   \n",
       "14               Data Analyst (Business Intelligence)   \n",
       "15                        Data Engineer - Entry Level   \n",
       "16                      Data Visualization Specialist   \n",
       "17                        Data Engineer - Entry Level   \n",
       "18                          PowerBI/PowerApp Engineer   \n",
       "19                                       Data Analyst   \n",
       "20                                        AI Engineer   \n",
       "21                                  Data Analyst Lead   \n",
       "22                                     Data Scientist   \n",
       "23                              Data Science Graduate   \n",
       "24                                      Data Engineer   \n",
       "25                                   Associate, CPS&O   \n",
       "26          Business Data Scientist, Machine Learning   \n",
       "27                                       Data Analyst   \n",
       "28                      Football Operations Assistant   \n",
       "29               Business Operations Analyst (Remote)   \n",
       "30  Data Analyst (Excel and Power BI) - Hybrid - B...   \n",
       "31                                     Data Analyst I   \n",
       "32                       Data Analytics and Reporting   \n",
       "33                                       Data Analyst   \n",
       "34          Business Data Scientist, Machine Learning   \n",
       "35                                       Data Analyst   \n",
       "36                              Data Analyst (Remote)   \n",
       "37                                Data Engineer Co-Op   \n",
       "38                                   Business Analyst   \n",
       "39                                       Data Analyst   \n",
       "40                              Business Data Analyst   \n",
       "41                                       Data Analyst   \n",
       "42                                       Data Analyst   \n",
       "43               Data Visualization Developer Analyst   \n",
       "44                                       Data Analyst   \n",
       "45                                       Data Analyst   \n",
       "46  Data Science Intern, Decisions - Product (Summ...   \n",
       "47                                  Reporting Analyst   \n",
       "48                      Business Intelligence Analyst   \n",
       "49                                       Data Analyst   \n",
       "50                     Analista de Datos Estad√≠sticos   \n",
       "51                                       Data Analyst   \n",
       "52                       Data Scientist (Entry Level)   \n",
       "53                                       Data Analyst   \n",
       "54                                   Sr. Data Analyst   \n",
       "55                                     Data Scientist   \n",
       "56                   Data Analytics Consultant Intern   \n",
       "57                                       Data Analyst   \n",
       "58                                       Data Analyst   \n",
       "59                                       Data Analyst   \n",
       "\n",
       "                             Company                         Location  \n",
       "0                               UCLA                  Los Angeles, CA  \n",
       "1                          Petroplan                      Houston, TX  \n",
       "2                The Value Maximizer        New Jersey, United States  \n",
       "3                The Value Maximizer      Pennsylvania, United States  \n",
       "4                             Nestl√©                        Solon, OH  \n",
       "5                             Notion                     New York, NY  \n",
       "6                  Cantor Fitzgerald  New York City Metropolitan Area  \n",
       "7                 City National Bank                  Los Angeles, CA  \n",
       "8                             Notion                San Francisco, CA  \n",
       "9                         InterWorks                     Portland, OR  \n",
       "10                          Experian                    United States  \n",
       "11                  Bose Corporation                   Framingham, MA  \n",
       "12                              Crew                    Richfield, MN  \n",
       "13                  Bose Corporation                   Framingham, MA  \n",
       "14                           Philips                      Malvern, PA  \n",
       "15                        InterWorks                        Tulsa, OK  \n",
       "16  A3T (Agil3 Technology Solutions)                   Washington, DC  \n",
       "17                        InterWorks                Oklahoma City, OK  \n",
       "18              Toyota North America                        Plano, TX  \n",
       "19                    Largeton Group                     Richmond, VA  \n",
       "20                          LinkedIn                    Sunnyvale, CA  \n",
       "21                          Datafied                      Anaheim, CA  \n",
       "22                             MLabs                     New York, NY  \n",
       "23        Hewlett Packard Enterprise                       Spring, TX  \n",
       "24              Toyota North America                        Plano, TX  \n",
       "25                           Netflix                  Los Angeles, CA  \n",
       "26                            Google                San Francisco, CA  \n",
       "27                     Talent Groups     Massachusetts, United States  \n",
       "28                      Dallas Bulls                       Dallas, TX  \n",
       "29                          DataBank                       Dallas, TX  \n",
       "30                         ideaHelix           San Francisco Bay Area  \n",
       "31                City National Bank                       Newark, DE  \n",
       "32                         U.S. Bank                  Minneapolis, MN  \n",
       "33                Prime 8 Consulting                    United States  \n",
       "34                            Google                   Washington, DC  \n",
       "35      Shaker Recruitment Marketing                     Oak Park, IL  \n",
       "36                  Desire Home Care                    United States  \n",
       "37                  Bose Corporation                   Framingham, MA  \n",
       "38              Toyota North America                        Plano, TX  \n",
       "39             World Wide Technology        California, United States  \n",
       "40               Digital Prospectors                   Greater Boston  \n",
       "41             World Wide Technology        Washington, United States  \n",
       "42             World Wide Technology          New York, United States  \n",
       "43                         H&R Block          Missouri, United States  \n",
       "44             World Wide Technology        New Jersey, United States  \n",
       "45                          Air Apps                San Francisco, CA  \n",
       "46                              Lyft         San Francisco County, CA  \n",
       "47  Stefanini North America and APAC                       Newark, NJ  \n",
       "48                United Wheels Inc.                   Miamisburg, OH  \n",
       "49             World Wide Technology             Texas, United States  \n",
       "50                         trabajito                   Santa Cruz, CA  \n",
       "51             World Wide Technology           Florida, United States  \n",
       "52                               ICF                       Reston, VA  \n",
       "53             World Wide Technology          Illinois, United States  \n",
       "54                     Verse Medical                     New York, NY  \n",
       "55                              Visa                  Foster City, CA  \n",
       "56                          Allstate                    United States  \n",
       "57             World Wide Technology           Georgia, United States  \n",
       "58             World Wide Technology              Ohio, United States  \n",
       "59             World Wide Technology          Maryland, United States  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example to call the function\n",
    "\n",
    "results = scrape_linkedin_job_search('data%20analysis')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "\n",
    "The first challenge for you is to update the `scrape_linkedin_job_search` function by adding a new parameter called `num_pages`. This will allow you to search more than 25 jobs with this function. Suggested steps:\n",
    "\n",
    "1. Go to https://www.linkedin.com/jobs/search/?keywords=data%20analysis in your browser.\n",
    "1. Scroll down the left panel and click the page 2 link. Look at how the URL changes and identify the page offset parameter.\n",
    "1. Add `num_pages` as a new param to the `scrape_linkedin_job_search` function. Update the function code so that it uses a \"for\" loop to retrieve several pages of search results.\n",
    "1. Test your new function by scraping 5 pages of the search results.\n",
    "\n",
    "Hint: Prepare for the case where there are less than 5 pages of search results. Your function should be robust enough to **not** trigger errors. Simply skip making additional searches and return all results if the search already reaches the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_linkedin_job_search(keywords, num_pages):\n",
    "    records = []\n",
    "    for page in range(num_pages):\n",
    "        # Define the base url to be scraped.\n",
    "        # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "        try:\n",
    "            BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "            \n",
    "            # Assemble the full url with parameters\n",
    "            scrape_url = ''.join([BASE_URL, 'keywords=', keywords, \"&start=\", str(page*25)])\n",
    "        \n",
    "            # Create a request to get the data from the server \n",
    "            page = requests.get(scrape_url)\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "            # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "            # Then in each job card, extract the job title, company, and location data.\n",
    "            titles = []\n",
    "            companies = []\n",
    "            locations = []\n",
    "            for card in soup.select(\"div.job-search-card\"):\n",
    "                title = card.select(\"h3\", recursive=False)[0].get_text().strip()\n",
    "                company = card.select(\"h4\", recursive=False)[0].get_text().strip()\n",
    "                location = card.select(\"span.job-search-card__location\")[0].get_text().strip()\n",
    "                titles.append(title)\n",
    "                companies.append(company)\n",
    "                locations.append(location)\n",
    "        \n",
    "                records.append({\n",
    "                    \"Title\": title,\n",
    "                    \"Company\": company,\n",
    "                    \"Location\": location\n",
    "                })\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        # Return dataframe\n",
    "    return pd.DataFrame(records, columns=[\"Title\", \"Company\", \"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Research Data Analyst</td>\n",
       "      <td>UCLA</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Petroplan</td>\n",
       "      <td>Houston, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>The Value Maximizer</td>\n",
       "      <td>New Jersey, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>The Value Maximizer</td>\n",
       "      <td>Pennsylvania, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Intern (Winter or Summer 2026)</td>\n",
       "      <td>Notion</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Verse Medical</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Foster City, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Georgia, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Maryland, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Data Analytics Consultant Intern</td>\n",
       "      <td>Allstate</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title                Company  \\\n",
       "0                          Research Data Analyst                   UCLA   \n",
       "1                                   Data Analyst              Petroplan   \n",
       "2                                 Data Scientist    The Value Maximizer   \n",
       "3                                 Data Scientist    The Value Maximizer   \n",
       "4    Data Science Intern (Winter or Summer 2026)                 Notion   \n",
       "..                                           ...                    ...   \n",
       "295                             Sr. Data Analyst          Verse Medical   \n",
       "296                               Data Scientist                   Visa   \n",
       "297                                 Data Analyst  World Wide Technology   \n",
       "298                                 Data Analyst  World Wide Technology   \n",
       "299             Data Analytics Consultant Intern               Allstate   \n",
       "\n",
       "                        Location  \n",
       "0                Los Angeles, CA  \n",
       "1                    Houston, TX  \n",
       "2      New Jersey, United States  \n",
       "3    Pennsylvania, United States  \n",
       "4                   New York, NY  \n",
       "..                           ...  \n",
       "295                 New York, NY  \n",
       "296              Foster City, CA  \n",
       "297       Georgia, United States  \n",
       "298      Maryland, United States  \n",
       "299                United States  \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scrape_linkedin_job_search('data%20analysis', 5)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "Further improve your function so that it can search jobs in a specific country. Add the 3rd param to your function called `country`. The steps are identical to those in Challange 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_linkedin_job_search(keywords, num_pages, country):\n",
    "    records = []\n",
    "    for page in range(num_pages):\n",
    "        # Define the base url to be scraped.\n",
    "        # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "        try:\n",
    "            BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "            \n",
    "            # Assemble the full url with parameters\n",
    "            scrape_url = ''.join([BASE_URL, 'keywords=', keywords, \"&location=\", country, \"&start=\", str(page*25)])\n",
    "        \n",
    "            # Create a request to get the data from the server \n",
    "            page = requests.get(scrape_url)\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "            # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "            # Then in each job card, extract the job title, company, and location data.\n",
    "            titles = []\n",
    "            companies = []\n",
    "            locations = []\n",
    "            for card in soup.select(\"div.job-search-card\"):\n",
    "                title = card.select(\"h3\", recursive=False)[0].get_text().strip()\n",
    "                company = card.select(\"h4\", recursive=False)[0].get_text().strip()\n",
    "                location = card.select(\"span.job-search-card__location\")[0].get_text().strip()\n",
    "                titles.append(title)\n",
    "                companies.append(company)\n",
    "                locations.append(location)\n",
    "        \n",
    "                records.append({\n",
    "                    \"Title\": title,\n",
    "                    \"Company\": company,\n",
    "                    \"Location\": location\n",
    "                })\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        # Return dataframe\n",
    "    return pd.DataFrame(records, columns=[\"Title\", \"Company\", \"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equity Research</td>\n",
       "      <td>Institute of Finance and Economics (IFE)</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Happy Mammoth</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product Analyst - (Logistics, Customer)</td>\n",
       "      <td>Delivery Hero</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst (m/f/d)</td>\n",
       "      <td>TOPdesk</td>\n",
       "      <td>Kaiserslautern, Rhineland-Palatinate, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Strategic researcher (m/f/d)</td>\n",
       "      <td>Omio</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Director of Artificial Intelligence</td>\n",
       "      <td>AI Futures</td>\n",
       "      <td>Cologne Bonn Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Business Analyst (m/w/d)</td>\n",
       "      <td>Swell, Inc.</td>\n",
       "      <td>Bad Schwalbach, Hesse, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>(Junior) Project &amp; Data Analyst - LSCM (m/f/d)</td>\n",
       "      <td>Bridgestone EMEA</td>\n",
       "      <td>Frankfurt am Main, Hesse, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Investment Analyst | Single Family Office</td>\n",
       "      <td>THRONSBERG | Private Capital Recruitment</td>\n",
       "      <td>Hamburg, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Junior Market Research Consultant (m/f/d)</td>\n",
       "      <td>Factworks</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title  \\\n",
       "0                                   Equity Research   \n",
       "1                                      Data Analyst   \n",
       "2           Product Analyst - (Logistics, Customer)   \n",
       "3                              Data Analyst (m/f/d)   \n",
       "4                      Strategic researcher (m/f/d)   \n",
       "..                                              ...   \n",
       "275             Director of Artificial Intelligence   \n",
       "276                        Business Analyst (m/w/d)   \n",
       "277  (Junior) Project & Data Analyst - LSCM (m/f/d)   \n",
       "278       Investment Analyst | Single Family Office   \n",
       "279       Junior Market Research Consultant (m/f/d)   \n",
       "\n",
       "                                      Company  \\\n",
       "0    Institute of Finance and Economics (IFE)   \n",
       "1                               Happy Mammoth   \n",
       "2                               Delivery Hero   \n",
       "3                                     TOPdesk   \n",
       "4                                        Omio   \n",
       "..                                        ...   \n",
       "275                                AI Futures   \n",
       "276                               Swell, Inc.   \n",
       "277                          Bridgestone EMEA   \n",
       "278  THRONSBERG | Private Capital Recruitment   \n",
       "279                                 Factworks   \n",
       "\n",
       "                                          Location  \n",
       "0                                          Germany  \n",
       "1                          Berlin, Berlin, Germany  \n",
       "2                          Berlin, Berlin, Germany  \n",
       "3    Kaiserslautern, Rhineland-Palatinate, Germany  \n",
       "4                          Berlin, Berlin, Germany  \n",
       "..                                             ...  \n",
       "275                            Cologne Bonn Region  \n",
       "276                 Bad Schwalbach, Hesse, Germany  \n",
       "277              Frankfurt am Main, Hesse, Germany  \n",
       "278                               Hamburg, Germany  \n",
       "279                        Berlin, Berlin, Germany  \n",
       "\n",
       "[280 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scrape_linkedin_job_search('data%20analysis', 5, \"Germany\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "Add the 4th param called `num_days` to your function to allow it to search jobs posted in the past X days. Note that in the LinkedIn job search the searched timespan is specified with the following param:\n",
    "\n",
    "```\n",
    "f_TPR=r259200\n",
    "```\n",
    "\n",
    "The number part in the param value is the number of seconds. 259,200 seconds equal to 3 days. You need to convert `num_days` to number of seconds and supply that info to LinkedIn job search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_linkedin_job_search(keywords, num_pages, country, num_days):\n",
    "    records = []\n",
    "    for page in range(num_pages):\n",
    "        # Define the base url to be scraped.\n",
    "        # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "        try:\n",
    "            BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "            \n",
    "            # Assemble the full url with parameters\n",
    "            scrape_url = ''.join([BASE_URL, 'keywords=', keywords, \"&location=\", country, \"&f_TPR=r\", str(num_days*86400), \"&start=\", str(page*25)])\n",
    "        \n",
    "            # Create a request to get the data from the server \n",
    "            page = requests.get(scrape_url)\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "            # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "            # Then in each job card, extract the job title, company, and location data.\n",
    "            titles = []\n",
    "            companies = []\n",
    "            locations = []\n",
    "            for card in soup.select(\"div.job-search-card\"):\n",
    "                title = card.select(\"h3\", recursive=False)[0].get_text().strip()\n",
    "                company = card.select(\"h4\", recursive=False)[0].get_text().strip()\n",
    "                location = card.select(\"span.job-search-card__location\")[0].get_text().strip()\n",
    "                titles.append(title)\n",
    "                companies.append(company)\n",
    "                locations.append(location)\n",
    "        \n",
    "                records.append({\n",
    "                    \"Title\": title,\n",
    "                    \"Company\": company,\n",
    "                    \"Location\": location\n",
    "                })\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        # Return dataframe\n",
    "    return pd.DataFrame(records, columns=[\"Title\", \"Company\", \"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equity Research</td>\n",
       "      <td>Institute of Finance and Economics (IFE)</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product Analyst - (Logistics, Customer)</td>\n",
       "      <td>Delivery Hero</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strategic researcher (m/f/d)</td>\n",
       "      <td>Omio</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Equity Research Intern</td>\n",
       "      <td>Institute of Finance and Economics (IFE)</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marketing Data Analyst (m/f/d)</td>\n",
       "      <td>Pflegia</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>AI Innovator</td>\n",
       "      <td>CEF.AI</td>\n",
       "      <td>Munich, Bavaria, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Praktikum Strategy und M&amp;A (m/w/d)</td>\n",
       "      <td>Flip</td>\n",
       "      <td>Stuttgart, Baden-W√ºrttemberg, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Prozessingenieur (all gender)</td>\n",
       "      <td>ALTEN Germany</td>\n",
       "      <td>Greater Munich Metropolitan Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Senior Research Engineer</td>\n",
       "      <td>DeepRec.ai</td>\n",
       "      <td>Greater Munich Metropolitan Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Artificial Intelligence Engineer</td>\n",
       "      <td>X4 Technology</td>\n",
       "      <td>Greater Munich Metropolitan Area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title  \\\n",
       "0                            Equity Research   \n",
       "1    Product Analyst - (Logistics, Customer)   \n",
       "2               Strategic researcher (m/f/d)   \n",
       "3                     Equity Research Intern   \n",
       "4             Marketing Data Analyst (m/f/d)   \n",
       "..                                       ...   \n",
       "109                             AI Innovator   \n",
       "110       Praktikum Strategy und M&A (m/w/d)   \n",
       "111            Prozessingenieur (all gender)   \n",
       "112                 Senior Research Engineer   \n",
       "113         Artificial Intelligence Engineer   \n",
       "\n",
       "                                      Company  \\\n",
       "0    Institute of Finance and Economics (IFE)   \n",
       "1                               Delivery Hero   \n",
       "2                                        Omio   \n",
       "3    Institute of Finance and Economics (IFE)   \n",
       "4                                     Pflegia   \n",
       "..                                        ...   \n",
       "109                                    CEF.AI   \n",
       "110                                      Flip   \n",
       "111                             ALTEN Germany   \n",
       "112                                DeepRec.ai   \n",
       "113                             X4 Technology   \n",
       "\n",
       "                                  Location  \n",
       "0                                  Germany  \n",
       "1                  Berlin, Berlin, Germany  \n",
       "2                  Berlin, Berlin, Germany  \n",
       "3                                  Germany  \n",
       "4                  Berlin, Berlin, Germany  \n",
       "..                                     ...  \n",
       "109               Munich, Bavaria, Germany  \n",
       "110  Stuttgart, Baden-W√ºrttemberg, Germany  \n",
       "111       Greater Munich Metropolitan Area  \n",
       "112       Greater Munich Metropolitan Area  \n",
       "113       Greater Munich Metropolitan Area  \n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scrape_linkedin_job_search('data%20analysis', 2, \"Germany\", 2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "Allow your function to also retrieve the \"Seniority Level\" of each job searched. Note that the Seniority Level info is not in the initial search results. You need to make a separate search request for each job card based on the `currentJobId` value which you can extract from the job card HTML.\n",
    "\n",
    "After you obtain the Seniority Level info, update the function and add it to a new column of the returned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_linkedin_job_search(keywords, num_pages, country, num_days):\n",
    "    records = []\n",
    "    for page in range(num_pages):\n",
    "        # Define the base url to be scraped.\n",
    "        # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "        try:\n",
    "            BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "            \n",
    "            # Assemble the full url with parameters\n",
    "            scrape_url = ''.join([BASE_URL, 'keywords=', keywords, \"&location=\", country, \"&f_TPR=r\", str(num_days*86400), \"&start=\", str(page*25)])\n",
    "        \n",
    "            # Create a request to get the data from the server \n",
    "            page = requests.get(scrape_url)\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "            # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "            # Then in each job card, extract the job title, company, and location data.\n",
    "            titles = []\n",
    "            companies = []\n",
    "            locations = []\n",
    "            for card in soup.select(\"div.job-search-card\"):\n",
    "                title = card.select(\"h3\", recursive=False)[0].get_text().strip()\n",
    "                company = card.select(\"h4\", recursive=False)[0].get_text().strip()\n",
    "                location = card.select(\"span.job-search-card__location\")[0].get_text().strip()\n",
    "                titles.append(title)\n",
    "                companies.append(company)\n",
    "                locations.append(location)\n",
    "                \n",
    "                currentjobid = card[\"data-entity-urn\"].split(\":\")[-1]\n",
    "                job_url = ''.join([\"https://www.linkedin.com/jobs/view/\", currentjobid])\n",
    "                page = requests.get(job_url)\n",
    "                soup = BeautifulSoup(page.text, 'html.parser')\n",
    "                seniority = soup.select(\"li.description__job-criteria-item h3\")[0].parent.select(\"span\")[0].get_text().strip()\n",
    "                \n",
    "                records.append({\n",
    "                    \"Title\": title,\n",
    "                    \"Company\": company,\n",
    "                    \"Location\": location,\n",
    "                    \"Seniority level\":seniority\n",
    "                })\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        # Return dataframe\n",
    "    return pd.DataFrame(records, columns=[\"Title\", \"Company\", \"Location\", \"Seniority level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Seniority level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equity Research</td>\n",
       "      <td>Institute of Finance and Economics (IFE)</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product Analyst - (Logistics, Customer)</td>\n",
       "      <td>Delivery Hero</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strategic researcher (m/f/d)</td>\n",
       "      <td>Omio</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>Internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Equity Research Intern</td>\n",
       "      <td>Institute of Finance and Economics (IFE)</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marketing Data Analyst (m/f/d)</td>\n",
       "      <td>Pflegia</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>AI Innovator</td>\n",
       "      <td>CEF.AI</td>\n",
       "      <td>Munich, Bavaria, Germany</td>\n",
       "      <td>Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Praktikum Strategy und M&amp;A (m/w/d)</td>\n",
       "      <td>Flip</td>\n",
       "      <td>Stuttgart, Baden-W√ºrttemberg, Germany</td>\n",
       "      <td>Not Applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Prozessingenieur (all gender)</td>\n",
       "      <td>ALTEN Germany</td>\n",
       "      <td>Greater Munich Metropolitan Area</td>\n",
       "      <td>Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Senior Research Engineer</td>\n",
       "      <td>DeepRec.ai</td>\n",
       "      <td>Greater Munich Metropolitan Area</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Data Engineer - Entry-Level (all genders)</td>\n",
       "      <td>Chrono24</td>\n",
       "      <td>Karlsruhe, Baden-W√ºrttemberg, Germany</td>\n",
       "      <td>Entry level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Title  \\\n",
       "0                              Equity Research   \n",
       "1      Product Analyst - (Logistics, Customer)   \n",
       "2                 Strategic researcher (m/f/d)   \n",
       "3                       Equity Research Intern   \n",
       "4               Marketing Data Analyst (m/f/d)   \n",
       "..                                         ...   \n",
       "109                               AI Innovator   \n",
       "110         Praktikum Strategy und M&A (m/w/d)   \n",
       "111              Prozessingenieur (all gender)   \n",
       "112                   Senior Research Engineer   \n",
       "113  Data Engineer - Entry-Level (all genders)   \n",
       "\n",
       "                                      Company  \\\n",
       "0    Institute of Finance and Economics (IFE)   \n",
       "1                               Delivery Hero   \n",
       "2                                        Omio   \n",
       "3    Institute of Finance and Economics (IFE)   \n",
       "4                                     Pflegia   \n",
       "..                                        ...   \n",
       "109                                    CEF.AI   \n",
       "110                                      Flip   \n",
       "111                             ALTEN Germany   \n",
       "112                                DeepRec.ai   \n",
       "113                                  Chrono24   \n",
       "\n",
       "                                  Location   Seniority level  \n",
       "0                                  Germany        Internship  \n",
       "1                  Berlin, Berlin, Germany  Mid-Senior level  \n",
       "2                  Berlin, Berlin, Germany        Internship  \n",
       "3                                  Germany        Internship  \n",
       "4                  Berlin, Berlin, Germany         Associate  \n",
       "..                                     ...               ...  \n",
       "109               Munich, Bavaria, Germany         Associate  \n",
       "110  Stuttgart, Baden-W√ºrttemberg, Germany    Not Applicable  \n",
       "111       Greater Munich Metropolitan Area         Associate  \n",
       "112       Greater Munich Metropolitan Area  Mid-Senior level  \n",
       "113  Karlsruhe, Baden-W√ºrttemberg, Germany       Entry level  \n",
       "\n",
       "[114 rows x 4 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scrape_linkedin_job_search('data%20analysis', 2, \"Germany\", 2)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
